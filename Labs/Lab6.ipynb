{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3af00e41-479d-479b-880d-634633bc4c6e",
   "metadata": {},
   "source": [
    "# LAB-6: Basics of Deep Learning\n",
    "\n",
    "### Objective\n",
    "\n",
    "We investigate a regression task by a basic deep learning architecture in this lab session. You need to implement the neural network from scratch by only using numpy package. \n",
    "\n",
    "### General Announcements\n",
    "\n",
    "* The exercises on this sheet are graded by a maximum of **10 points**. You will be asked to implement several functions.\n",
    "* Team work is not allowed! Everybody implements his/her own code. Discussing issues with others is fine, sharing code with others is not. \n",
    "* If you use any code fragments found on the Internet, make sure you reference them properly.\n",
    "* You can send your questions via email to the TAs until the deadline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40124f22-f31a-486b-ba94-96a67c45036a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd # Only for print function - DO NOT USE!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c49288d-0404-401e-b789-36d86e7c8449",
   "metadata": {},
   "source": [
    "# 1) Generating a toy dataset\n",
    "- Generate a dataset randomly by the help of numpy. (1 point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b66a4a25-44bc-415e-80cc-6273491a3e95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 10) (1,)\n"
     ]
    }
   ],
   "source": [
    "def generate_data(num_samples: int, num_features: int) -> tuple:\n",
    "    \"\"\"\n",
    "    Inputs: \n",
    "        - Number of Samples (dtype: Integer)\n",
    "        - Number of dimension in Features/Data (dtype: Integer)\n",
    "    Outputs:\n",
    "        - data (numpy.ndarray | dtype: numpy.float | Shape=(num_sample, num_feature))\n",
    "        - labels (numpy.ndarray | dtype: numpy.float | Shape=(num_sample))\n",
    "    \"\"\"\n",
    "    np.random.seed(42) # Keep the seed the same\n",
    "    # Insert Your Code Here!\n",
    "    data = np.random.rand(num_samples,num_features)\n",
    "    labels = np.random.randint(low=0,high=2,size=num_samples)\n",
    "    return (data, labels)\n",
    "\n",
    "# For checking - # DO NOT MODIFY\n",
    "X, Y = generate_data(1, 10)\n",
    "print(X.shape, Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e0142d-28cb-479d-bbc8-46914075ad72",
   "metadata": {},
   "source": [
    "# 2) Designing a Deep Learning from Scratch\n",
    "- All modules in a deep learning models have a common structure. You can find it below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9aaf3c44-1dec-44c8-8a71-6cefbee117c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT MODIFY\n",
    "class GenericModule:\n",
    "    def forward(self, data: np.ndarray) -> np.ndarray:\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    def backward(self, grad: np.ndarray) -> np.ndarray:\n",
    "        raise NotImplementedError\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ccf84a-ff47-460f-ba9a-5873bddcce2c",
   "metadata": {},
   "source": [
    "- Now, you need to implement the module by using numpy functions only.\n",
    "    - Implement ReLU which is the function: $f(x) = max(0, x)$ (1 point for forward & 1 point for backward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d57fe23-54d4-43f9-a688-dd591d24292a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      input    output\n",
      "0 -0.145597  0.000000\n",
      "1  0.430578  0.430578\n",
      "2  0.211857  0.211857\n",
      "3  0.078522  0.078522\n",
      "4 -0.364118  0.000000\n",
      "5 -0.364142  0.000000\n",
      "6 -0.462053  0.000000\n",
      "7  0.346039  0.346039\n",
      "8  0.080978  0.080978\n",
      "9  0.187936  0.187936\n"
     ]
    }
   ],
   "source": [
    "class ReLU(GenericModule):\n",
    "    def __init__(self, name, shape):\n",
    "        self.name = name\n",
    "        # Insert Your Code Here!\n",
    "        self.mask = None\n",
    "        \n",
    "    def forward(self, data):\n",
    "        # Insert Your Code Here!\n",
    "        self.mask = data > 0\n",
    "        out = np.maximum(data,0)\n",
    "        return out  # Note that for the backpropagation you need to remember which indexes were not mask by the ReLU\n",
    "    \n",
    "    def backward(self, grad):\n",
    "        \n",
    "        # Insert Your Code Here!\n",
    "        back = grad * self.mask\n",
    "        return back\n",
    "\n",
    "# Checking Module - DO NOT MODIFY\n",
    "obj = ReLU('Temporary', 10)\n",
    "output = obj.forward(X[0] - X[0].mean())\n",
    "df_temp = pd.DataFrame({'input': X[0] - X[0].mean(), 'output': output})\n",
    "print(df_temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe8d47e4-7bcb-4850-8c19-8ddaccfea3d5",
   "metadata": {},
   "source": [
    "- Implement dense layer: $f(x) = (w \\cdot x) + b$ (1 point for forward & 1 point for backward)\n",
    "- Initialize the weight and bias values uniformly random in between (-0.5, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3384c872-d86a-40f2-959f-0b80c67243d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 32) (10, 32) (1, 32)\n"
     ]
    }
   ],
   "source": [
    "class Dense(GenericModule):\n",
    "    def __init__(self, name, in_size, out_size):\n",
    "        self.name=name\n",
    "        np.random.seed(42) # Keep the seed the same\n",
    "        self.w = np.random.randn(in_size, out_size) # Random initialization.\n",
    "        self.b = np.zeros((1,out_size))\n",
    "        self.x = None  # Empty array for backprop\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Insert Your Code Here!\n",
    "        self.x = x  # save for backprop\n",
    "        out = np.dot(self.x,self.w) + self.b\n",
    "        return out\n",
    "    \n",
    "    def backward(self, grad): #https://towardsdatascience.com/math-neural-network-from-scratch-in-python-d6da9f29ce65\n",
    "        grad_x = np.dot(grad, self.w.T)\n",
    "        self.grad_w = np.dot(self.x.T, grad)\n",
    "        self.grad_b = np.sum(grad, axis=0, keepdims=True)\n",
    "        return grad_x\n",
    "\n",
    "# Checking Module - DO NOT MODIFY\n",
    "obj = Dense('Temporary', 10, 32)\n",
    "output = obj.forward(X[0] - X[0].mean())\n",
    "print(output.shape, obj.w.shape, obj.b.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2510683b-f3fa-4a7b-a206-54bd12b22bda",
   "metadata": {},
   "source": [
    "- Implement L2 loss function: $L(x, y) = |x - y|_2$ (1 point for forward & 1 point for backward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "96a53ae6-24ea-4fcf-9f3b-8738c493c954",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81 -18\n"
     ]
    }
   ],
   "source": [
    "class L2_loss(GenericModule):\n",
    "    def forward(self, x, y):\n",
    "        # Insert Your Code Here!\n",
    "        self.x = x\n",
    "        self.y = y \n",
    "        diff = x - y\n",
    "        loss = np.sum(diff ** 2)\n",
    "        return loss\n",
    "    \n",
    "    def backward(self):\n",
    "        # Insert Your Code Here!\n",
    "        gradient = 2 * (self.x - self.y)\n",
    "        return gradient\n",
    "    \n",
    "# Checking Module - DO NOT MODIFY\n",
    "obj = L2_loss()\n",
    "\n",
    "output = obj.forward(np.ones_like(Y)[0], 10 * np.ones_like(Y)[0])\n",
    "\n",
    "print(output, obj.backward())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbdf7d1b-22cf-43e7-9dea-63437c698948",
   "metadata": {},
   "source": [
    "# 3) Form a neural network\n",
    "- Design an architecture as a list by using dense, relu layers (1 point)\n",
    "    - Use the given hyper-parameters during designing: \n",
    "        1) Dense (??, 32)\n",
    "        2) ReLU (??)\n",
    "        3) Dense (??, 1)\n",
    "    - Re-generate the dataset\n",
    "        - Number of Samples = 4\n",
    "        - Number of Features = 10\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c8d3a48a-8280-40f0-9ce8-c7b97841e694",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = [Dense('Dense1', 10, 32),\n",
    "        ReLU('ReLU1', 32),\n",
    "        Dense('Dense2', 32, 1)]\n",
    "X, Y = generate_data(4, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70338330-81a8-4a03-bc77-95fb3ed03e2d",
   "metadata": {},
   "source": [
    "- Train the network (1 point for forward & backward passes)\n",
    "- Implement gradient decent algorithm for dense layerslayerlayer (1 point)\n",
    "- Note that please run the cell below once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0afa1c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper-Paraters for Training\n",
    "learning_rate = 0.01\n",
    "num_epoch = 10\n",
    "\n",
    "# Training Phase\n",
    "for epoch_no in range(num_epoch):\n",
    "    for sample_idx in range(1):\n",
    "        x = X[sample_idx]\n",
    "        y = Y[sample_idx]\n",
    "\n",
    "        # Forward Pass\n",
    "        for layer in net:\n",
    "            x = layer.forward(x)\n",
    "            # Insert Your Code Here!\n",
    "\n",
    "        loss_value = x # Insert Your Code Here!\n",
    "        print(epoch_no, loss_value)\n",
    "\n",
    "        # Backward Pass\n",
    "        grad = obj.backward()\n",
    "        for layer in net[::-1]:\n",
    "            layer.backward(grad)\n",
    "            # Insert Your Code Here!\n",
    "            \n",
    "            if isinstance(layer, Dense):  #?\n",
    "                \n",
    "                # Optimization: Gradient Decent\n",
    "                # Insert Your Code Here!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
